# 🤖 Copilot Consistency Checklist

> **Purpose**: Comprehensive checklist for AI assistants to ensure all documentation, tests, help text, and code examples stay synchronized with the current codebase implementation.

## 📋 **Pre-Change Analysis**

Before making any significant changes, AI should check these areas for current state:

### **Core Documentation**

- [ ] `README.md` - Installation, usage examples, feature descriptions
- [ ] `docs/getting-started.md` - User setup and first-run instructions
- [ ] `.testing-framework.md` - Testing procedures and examples
- [ ] `.persona-based-testing-guide.md` - AI testing methodology
- [ ] `docs/security-assessment.md` - Security features and analysis
- [ ] `VERSION_GUIDE.md` - Versioning workflow and release process
- [ ] `TODO.md` - Known issues and planned features

### **AI Instructions & Behavior**

- [ ] `.github/copilot-instructions.md` - Coding style, principles, and guidelines
- [ ] This file (`.copilot-consistency-checklist.md`) - Keep updated with new areas

### **CLI Help & User Experience**

- [ ] `cmd/root.go` - Root command help text and long description
- [ ] All `cmd/*.go` files - Individual command help, examples, and usage
- [ ] Error messages throughout codebase - Ensure helpful and consistent
- [ ] First-run experience messaging - Setup prompts and guidance

### **Testing & Validation**

- [ ] `integration/*.go` - Integration tests with realistic scenarios
- [ ] `*_test.go` files - Unit tests covering edge cases
- [ ] `Makefile` - Build targets, test commands, and workflows
- [ ] Testing framework documentation accuracy

### **Configuration & Metadata**

- [ ] `go.mod` - Dependencies and Go version
- [ ] Build tags and compilation flags
- [ ] File permissions and security configurations
- [ ] `config.json` creation and template synchronization:
  - Auto-creation during first-run in `internal/first_run.go`
  - Template content matches documentation examples
  - `rotation_backup_count` default and documentation alignment
  - Token storage examples consistent across README and template

## 🔄 Copilot Consistency Validation Checklist

> **Purpose**: Ensure all documentation, tests, code, and examples remain synchronized after changes

### Pre-Validation Setup

🚨 **Environment Token Check**:
```bash
env | grep -i simple
# If SIMPLE_SECRETS_TOKEN is set, note it in validation results!
# It auto-authenticates and can affect example testing.
```

1. **Understand the scope of changes**:
   - What functionality was added/modified/removed?
   - Which files were directly changed?
   - What downstream effects might occur?

2. **Build the application** to ensure examples work:
   ```bash
   make dev
   ./simple-secrets version  # Should show dev-[commit]
   ```

## 🎯 **Specific Consistency Points**

### **Command Examples**
Ensure these are consistent across all documentation:
- Token format and length
- File paths (especially `~/.simple-secrets/`)
- Command syntax and flags
- Environment variable names (`SIMPLE_SECRETS_TOKEN`)

### **Feature Descriptions**
Keep these synchronized:
- Encryption details (AES-256-GCM)
- RBAC role descriptions (admin/reader permissions)
- Backup and rotation capabilities
- File structure and permissions
- **Concurrent operations handling** (file locking, race condition prevention)
- **Data integrity guarantees** (atomic operations, reload-before-write pattern)

### **User Experience Flow**
Maintain consistency in:
- First-run setup experience
- Authentication methods and precedence
- Error handling and recovery guidance
- Setup cancellation and restart procedures

## 🚨 **Critical Areas for Drift**

These areas are most prone to getting out of sync:

1. **CLI help text** vs **README examples**
2. **Error messages** vs **troubleshooting docs**
3. **Test procedures** vs **actual implementation**
4. **Help system** vs **actual functionality** (CRITICAL - testing foundation)
5. **Concurrent operations testing** vs **file locking implementation** (CRITICAL - data integrity)
6. **Feature lists** vs **implemented capabilities**
7. **Security claims** vs **actual security measures**

## 🔍 **Help System Consistency Validation**

Since `--help` traversal is the foundation of our testing frameworks, help text accuracy is critical:

### **Help Text Cross-Validation**
- [ ] **Help vs Implementation**: Every flag/option in help actually works
- [ ] **Help vs Examples**: All help examples execute successfully
- [ ] **Help vs Documentation**: README examples match help examples
- [ ] **Help vs Error Messages**: Help-suggested usage doesn't produce errors
- [ ] **Help vs Testing Framework**: All help commands covered in testing checklist

### **Command Help Consistency**
- [ ] **Flag descriptions**: Consistent flag descriptions across all commands
- [ ] **Usage patterns**: Consistent syntax patterns (e.g., `[command] [flags]`)
- [ ] **Global flags**: `--token`, `--help` work consistently across all commands
- [ ] **Example quality**: All examples use realistic, consistent data
- [ ] **Terminology**: Same terms used consistently (e.g., "secret" vs "value")

### **Help Accuracy Validation**
- [ ] **Feature completeness**: All implemented features mentioned in help
- [ ] **Deprecated features**: Old features removed from help if no longer supported
- [ ] **New feature documentation**: New functionality immediately added to help
- [ ] **Subcommand discovery**: `[command] --help` shows all available subcommands
- [ ] **Exit code documentation**: Help mentions expected exit codes where relevant

### **Help System Testing Integration**
- [ ] **Testing framework sync**: `.testing-framework.md` command inventory matches help
- [ ] **Persona-based framework sync**: `.persona-based-testing-guide.md` command discovery aligns with help
- [ ] **Pre-merge checklist**: Help validation included in consistency checks
- [ ] **Documentation links**: Help system references correct documentation URLs

### **Help Maintenance Process**
- [ ] **Code change trigger**: Any command/flag change triggers help text review
- [ ] **Help text location**: Identify where help text is defined in codebase
- [ ] **Help generation**: Verify if help is auto-generated or manually maintained
- [ ] **Review process**: Help text changes go through same review as code changes
4. **Feature lists** vs **implemented capabilities**
5. **Security claims** vs **actual security measures**

## 📝 **Automation Helpers**

### **Quick Consistency Check Commands**
```bash
# Verify all commands work as documented
grep -r "simple-secrets " docs/ | grep -E "^\s*\$|^\s*>"

# Check for outdated version references
grep -r "v[0-9]" docs/ README.md

# Find hardcoded paths that might need updating
grep -r "\.simple-secrets" docs/ README.md
```

### **Configuration File Validation**

Specific checks for config.json and related features:

```bash
# Test auto-creation during first-run
export SIMPLE_SECRETS_CONFIG_DIR=/tmp/test-config
echo "Y" | ./simple-secrets list users
cat /tmp/test-config/config.json  # Should contain commented examples

# Verify template content matches documentation
grep -A 20 '"rotation_backup_count"' README.md
grep -A 20 '"rotation_backup_count"' /tmp/test-config/config.json

# Check code synchronization
grep -n "rotation_backup_count" internal/first_run.go internal/rotation.go
grep -n "DefaultRotationBackupCount" internal/rotation.go
```

**Config.json Consistency Checklist:**

- [ ] **Template creation**: `createDefaultConfigFile()` in `internal/first_run.go` creates proper template
- [ ] **Content accuracy**: Comments and examples match README.md documentation
- [ ] **Default values**: `rotation_backup_count: 1` matches `DefaultRotationBackupCount` constant
- [ ] **Token examples**: Commented token example consistent across README and template
- [ ] **Documentation sync**: All three authentication methods clearly documented in both
- [ ] **Field validation**: Code validates rotation_backup_count values as documented
- [ ] **Config command coordination**: `simple-secrets config` output must match actual implementation:
  - Every option documented in config command actually works in code
  - Every configurable feature in code is documented in config command
  - Examples in config command match auto-created template structure
  - Default values in config command match code constants
  - Config command examples can be copied directly into config.json and work
  - Range limits mentioned in config command are enforced by validation code

### **Before/After Validation**

Always test these flows after changes:

- Fresh installation and first-run setup
- Basic CRUD operations with authentication
- Error scenarios with helpful messages
- All examples from documentation

## 🎯 **AI Assistant Guidelines**

When asked to make changes:

1. **Read first** - Check current state of all relevant documentation
2. **Plan changes** - Identify all areas that need updates
3. **Implement systematically** - Code first, then documentation
4. **Verify examples** - Test all documented procedures
5. **Cross-reference** - Ensure consistency across all materials

## 🔄 **Maintenance Schedule**

**After every significant change:**

- [ ] Run through this checklist
- [ ] Test at least one complete user journey
- [ ] Verify examples in documentation still work

**Periodic full review:**

- [ ] All documentation examples tested end-to-end
- [ ] All help text reviewed for accuracy
- [ ] All error messages checked for usefulness
- [ ] Testing frameworks validated against current implementation

---

**Last Updated**: September 20, 2025
**Next Review**: After next major feature addition or UX change
**Maintained by**: AI assistants working on this codebase
